{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras as keras\n",
    "from keras.applications import ResNet50\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Parameters\n",
    "batch_size = 8\n",
    "learning_rate = 0.0001\n",
    "EPOCHS =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory paths for the benign and malignant images\n",
    "benign_dir = 'Dataset/Benign Masses'\n",
    "malignant_dir = 'Dataset/Malignant Masses'\n",
    "\n",
    "# Target size for resizing\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Lists to store the images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Function to resize and process the images\n",
    "def process_image(image_path, label):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    images.append(resized_image)\n",
    "    labels.append(label)\n",
    "\n",
    "# Processing the benign images\n",
    "for filename in os.listdir(benign_dir):\n",
    "    image_path = os.path.join(benign_dir, filename)\n",
    "    process_image(image_path, label='benign')\n",
    "\n",
    "# Processing the malignant images\n",
    "for filename in os.listdir(malignant_dir):\n",
    "    image_path = os.path.join(malignant_dir, filename)\n",
    "    process_image(image_path, label='malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting lists to numpy arrays\n",
    "images = np.array(images)/255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "#One-hot-encoding our labels\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X contains your feature data and y contains your target labels\n",
    "trainX, testX, trainY, testY = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "trainAug = ImageDataGenerator(rotation_range=15, fill_mode = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(backbone, learning_rate=1e-4):\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,600,002\n",
      "Trainable params: 23,542,786\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "\n",
    "model = build_model(resnet ,learning_rate = 1e-4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.8004 - accuracy: 0.5517 - val_loss: 0.6963 - val_accuracy: 0.5172\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.5215 - accuracy: 0.7672 - val_loss: 0.7168 - val_accuracy: 0.5172\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.3489 - accuracy: 0.8922 - val_loss: 0.7917 - val_accuracy: 0.5172\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.3481 - accuracy: 0.8707 - val_loss: 0.6931 - val_accuracy: 0.5172\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.2713 - accuracy: 0.9009 - val_loss: 0.6981 - val_accuracy: 0.5345\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.2831 - accuracy: 0.8922 - val_loss: 0.7666 - val_accuracy: 0.4828\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.1355 - accuracy: 0.9569 - val_loss: 0.8394 - val_accuracy: 0.4828\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.1254 - accuracy: 0.9569 - val_loss: 0.8219 - val_accuracy: 0.4828\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0773 - accuracy: 0.9698 - val_loss: 0.8810 - val_accuracy: 0.4828\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.1947 - accuracy: 0.9224 - val_loss: 0.7617 - val_accuracy: 0.4828\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.1514 - accuracy: 0.9353 - val_loss: 0.7512 - val_accuracy: 0.5172\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.1459 - accuracy: 0.9397 - val_loss: 0.7834 - val_accuracy: 0.5172\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.1930 - accuracy: 0.9569 - val_loss: 0.8979 - val_accuracy: 0.5172\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.1254 - accuracy: 0.9569 - val_loss: 0.7873 - val_accuracy: 0.5172\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.1415 - accuracy: 0.9526 - val_loss: 0.9199 - val_accuracy: 0.5172\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.1655 - accuracy: 0.9440 - val_loss: 0.9399 - val_accuracy: 0.5172\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.1329 - accuracy: 0.9612 - val_loss: 0.7851 - val_accuracy: 0.5345\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.1528 - accuracy: 0.9526 - val_loss: 0.7171 - val_accuracy: 0.5345\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.1640 - accuracy: 0.9612 - val_loss: 0.7065 - val_accuracy: 0.6034\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.1618 - accuracy: 0.9526 - val_loss: 0.7599 - val_accuracy: 0.4828\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.1194 - accuracy: 0.9569 - val_loss: 0.7411 - val_accuracy: 0.4655\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.1194 - accuracy: 0.9526 - val_loss: 0.7935 - val_accuracy: 0.4655\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.0545 - accuracy: 0.9871 - val_loss: 0.7542 - val_accuracy: 0.5172\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.0275 - accuracy: 0.9871 - val_loss: 0.7238 - val_accuracy: 0.5345\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.0754 - accuracy: 0.9828 - val_loss: 0.6521 - val_accuracy: 0.5862\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 154s 5s/step - loss: 0.0983 - accuracy: 0.9655 - val_loss: 0.6663 - val_accuracy: 0.5862\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.0508 - accuracy: 0.9871 - val_loss: 0.6106 - val_accuracy: 0.6034\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.1226 - accuracy: 0.9741 - val_loss: 0.4970 - val_accuracy: 0.7414\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0517 - accuracy: 0.9871 - val_loss: 0.4541 - val_accuracy: 0.7414\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 42s 1s/step - loss: 0.0642 - accuracy: 0.9741 - val_loss: 0.4936 - val_accuracy: 0.7069\n",
      "2/2 [==============================] - 2s 861ms/step - loss: 0.4936 - accuracy: 0.7069\n",
      "Test Loss: 0.4936\n",
      "Test Accuracy: 0.7069\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "opt = Adam  (learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(\n",
    "    trainAug.flow(trainX, trainY, batch_size=batch_size),\n",
    "    steps_per_epoch=trainX.shape[0] / batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data = (testX, testY),\n",
    "    )\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(testX, testY)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
