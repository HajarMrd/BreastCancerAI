{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory paths for the benign and malignant images\n",
    "benign_dir = 'Dataset/Benign Masses'\n",
    "malignant_dir = 'Dataset/Malignant Masses'\n",
    "\n",
    "# Target size for resizing\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Lists to store the images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Function to resize and process the images\n",
    "def process_image(image_path, label):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    images.append(resized_image)\n",
    "    labels.append(label)\n",
    "\n",
    "# Processing the benign images\n",
    "for filename in os.listdir(benign_dir):\n",
    "    image_path = os.path.join(benign_dir, filename)\n",
    "    process_image(image_path, label='benign')\n",
    "\n",
    "# Processing the malignant images\n",
    "for filename in os.listdir(malignant_dir):\n",
    "    image_path = os.path.join(malignant_dir, filename)\n",
    "    process_image(image_path, label='malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting lists to numpy arrays\n",
    "images = np.array(images)/255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X contains your feature data and y contains your target labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "trainAug = ImageDataGenerator(rotation_range=15, fill_mode = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16 Model introduction\n",
    "baseModel = VGG16(weights = \"imagenet\", include_top = False, input_tensor=Input(shape = (224,224,3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the last layer of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting the basemodel (VGG16) to our output layer\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size = (4,4)) (headModel)\n",
    "headModel = Flatten(name = \"flatten\") (headModel)\n",
    "headModel = Dense(64, activation=\"relu\") (headModel)\n",
    "headModel = Dropout(0.5) (headModel)\n",
    "headModel = Dense(2, activation=\"softmax\") (headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the models\n",
    "model = Model(inputs = baseModel.input, outputs = headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing the baseModel layers\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling The model using Adam optimizer\n",
    "epochs = 25\n",
    "learning_rate = 0.001\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = Adam(learning_rate, decay_rate)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "#model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
